# -*- coding: utf-8 -*-
"""breast-cancer- (1).ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1SWHgrhAMIWkj2-EQmfJxeZH_XdXGPkd8

# Importing Necessary libraries
"""

!pip install opencv-python
!pip install numpy
!pip install pandas
!pip install matplotlib
!pip install seaborn
!pip install opencv-python
!pip install glob2
!pip install random2
!pip install scikit-learn
!pip install tensorflow
!pip install keras

# Commented out IPython magic to ensure Python compatibility.
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
# %matplotlib inline
import seaborn as sns
import cv2
import glob
import random
from os import listdir
from sklearn.metrics import classification_report
import tensorflow as tf
import keras.utils as image

"""# Loading Dataset"""

breast_img = glob.glob(r'C:\Users\bbalu\Desktop\Breast cancer\IDC_regular_ps50_idx5/**/*.png', recursive=True)

for imgname in breast_img[:3]:
    print(imgname)

"""# Visualizing Dataset"""

N_IDC = []
P_IDC = []

for img in breast_img:
    if img[-5] == '0' :
        N_IDC.append(img)

    elif img[-5] == '1' :
        P_IDC.append(img)
plt.figure(figsize = (15, 15))

some_non = np.random.randint(0, len(N_IDC), 18)
some_can = np.random.randint(0, len(P_IDC), 18)

s = 0
for num in some_non:

        img = image.load_img((N_IDC[num]), target_size=(100, 100))
        img = image.img_to_array(img)

        plt.subplot(6, 6, 2*s+1)
        plt.axis('off')
        plt.title('no cancer')
        plt.imshow(img.astype('uint8'))
        s += 1
s = 1
for num in some_can:

        img = image.load_img((P_IDC[num]), target_size=(100, 100))
        img = image.img_to_array(img)

        plt.subplot(6, 6, 2*s)
        plt.axis('off')
        plt.title('IDC (+)')
        plt.imshow(img.astype('uint8'))
        s += 1

NewN_IDC=N_IDC[:78786]
print(len(NewN_IDC))
print(len(P_IDC))

"""# Data Preprocessing"""

non_img_arr = []
can_img_arr = []

for img in NewN_IDC:

    n_img = cv2.imread(img, cv2.IMREAD_COLOR)
    n_img_size = cv2.resize(n_img, (50, 50), interpolation = cv2.INTER_LINEAR)
    non_img_arr.append([n_img_size, 0])

for img in P_IDC:
    c_img = cv2.imread(img, cv2.IMREAD_COLOR)
    c_img_size = cv2.resize(c_img, (50, 50), interpolation = cv2.INTER_LINEAR)
    can_img_arr.append([c_img_size, 1])

print(len(non_img_arr))
print(len(can_img_arr))
print(len(non_img_arr)+len(can_img_arr))

X = []
y = []

# Assuming non_img_arr and can_img_arr are lists of tuples
breast_img_arr = non_img_arr[:12389] + can_img_arr[:12389]
random.shuffle(breast_img_arr)

for feature, label in breast_img_arr:
    X.append(feature)
    y.append(label)

X = np.array(X)
y = np.array(y)

def describeData(a,b):
    print('Total number of images: {}'.format(len(a)))
    print('Number of IDC(-) Images: {}'.format(np.sum(b==0)))
    print('Number of IDC(+) Images: {}'.format(np.sum(b==1)))
    print('Image shape (Width, Height, Channels): {}'.format(a[0].shape))
describeData(X,y)

from sklearn.model_selection import train_test_split
X_train, X_test, Y_train, Y_test = train_test_split(X, y, test_size=0.3)

from tensorflow.keras.utils import to_categorical
Y_train = to_categorical(Y_train, num_classes = 2)
Y_test = to_categorical(Y_test, num_classes = 2)

print("Training Data Shape:", X_train.shape)
print("Testing Data Shape:", X_test.shape)

"""# Modeling"""

from sklearn.metrics import classification_report
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Conv2D,MaxPooling2D, Flatten, Dropout, BatchNormalization
from tensorflow.keras.optimizers import SGD
from tensorflow.keras.optimizers import Adam, SGD
from keras.metrics import binary_crossentropy
from tensorflow.keras.callbacks import EarlyStopping
from sklearn.metrics import confusion_matrix
import itertools

early_stop=EarlyStopping(monitor='val_loss',patience=5)
model = Sequential()
model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', input_shape=(50, 50, 3)))
model.add(BatchNormalization())
model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))
model.add(MaxPooling2D((2, 2)))
model.add(BatchNormalization())
model.add(Dropout(0.3))
model.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))
model.add(BatchNormalization())
model.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))
model.add(BatchNormalization())
model.add(MaxPooling2D((2, 2)))
model.add(Dropout(0.3))
model.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))
model.add(Flatten())
model.add(Dense(128, activation='relu', kernel_initializer='he_uniform'))
model.add(BatchNormalization())
model.add(Dense(64, activation='relu', kernel_initializer='he_uniform'))
model.add(BatchNormalization())
model.add(Dense(64, activation='relu', kernel_initializer='he_uniform'))
model.add(Dropout(0.3))
model.add(Dense(24, activation='relu', kernel_initializer='he_uniform'))
model.add(Dense(2, activation='softmax'))

model.compile(Adam(learning_rate=0.0001), loss='binary_crossentropy', metrics=['accuracy'])

model.summary()

history = model.fit(X_train, Y_train, validation_data = (X_test, Y_test), epochs = 50, batch_size = 35)

"""# Model Evaluation"""

plt.plot(history.history['accuracy'])
plt.plot(history.history['val_accuracy'])
plt.title('Model Accuracy')
plt.xlabel('epoch')
plt.ylabel('accuracy')
plt.legend(['train', 'test'], loc='upper left')
plt.show()

plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.title('Model Loss')
plt.xlabel('epoch')
plt.ylabel('loss')
plt.legend(['train', 'test'], loc='upper left')
plt.show()

from sklearn.metrics import accuracy_score
Y_pred = model.predict(X_test)
Y_pred_classes = np.argmax(Y_pred,axis = 1)
Y_true = np.argmax(Y_test,axis = 1)
# accuracy=accuracy_score(y_true=Y_true, y_pred=Y_pred)
# print(accuracy)
confusion_mtx = confusion_matrix(Y_true, Y_pred_classes)
f,ax = plt.subplots(figsize=(8,5))
sns.heatmap(confusion_mtx, annot=True, linewidths=0.01,cmap="BuPu",linecolor="gray", fmt= '.1f',ax=ax)
plt.xlabel("Predicted Label")
plt.ylabel("True Label")
plt.title("Confusion Matrix")
plt.show()

from sklearn.metrics import accuracy_score, confusion_matrix
# Y_pred = model.predict(X_test)
Y_pred_classes = np.argmax(Y_pred, axis=1)
Y_true = np.argmax(Y_test, axis=1)

confusion_mtx = confusion_matrix(Y_true, Y_pred_classes)

# calculate the percentage
confusion_mtx_percent = confusion_mtx.astype('float') / confusion_mtx.sum(axis=1)[:, np.newaxis] * 100

f, ax = plt.subplots(figsize=(8, 5))
sns.heatmap(confusion_mtx_percent, annot=True, linewidths=0.01, cmap="BuPu", linecolor="gray", fmt='.1f', ax=ax)
plt.xlabel("Predicted Label")
plt.ylabel("True Label")
plt.title("Confusion Matrix (Percentage)")
plt.show()

model.evaluate(X_test,Y_test)

preds = model.predict(X_test)

print("Y_test shape:", Y_test.shape)
print("preds shape:", preds.shape)

"""# Precision"""

threshold = 0.5
preds_binary = (preds > threshold).astype(int)

precision_positive = metrics.precision_score(Y_test[:, 1], preds_binary[:, 1], pos_label=1)
precision_negative = metrics.precision_score(Y_test[:, 0], preds_binary[:, 0], pos_label=0)

precision_positive, precision_negative

"""# Recall"""

recall_sensitivity = metrics.recall_score(Y_test[:, 1], preds_binary[:, 1], average='binary')
recall_specificity = metrics.recall_score(Y_test[:, 0], preds_binary[:, 0], average='binary')
recall_sensitivity, recall_specificity

"""# F1"""

f1_positive = metrics.f1_score(Y_test[:, 1], preds_binary[:, 1], average='binary')
f1_negative = metrics.f1_score(Y_test[:, 0], preds_binary[:, 0], average='binary')
f1_positive, f1_negative

"""# ROC and AUC score"""

from sklearn.datasets import load_breast_cancer
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split
from sklearn import metrics
import pandas as pd
import numpy as np
from matplotlib import pyplot as plt
import seaborn as sns
sns.set_style('darkgrid')

sns.set_style('darkgrid')
preds_train = model.predict(X_train)
# calculate prediction probability
prob_train = np.squeeze(preds_train[:,1].reshape(1,-1))
prob_test = np.squeeze(model.predict(X_test)[:,1].reshape(1,-1))
# false positive rate, true positive rate, thresholds
fpr1, tpr1, thresholds1 = metrics.roc_curve(Y_test[:, 1], prob_test)
fpr2, tpr2, thresholds2 = metrics.roc_curve(Y_train[:, 1], prob_train)
# auc score
auc1 = metrics.auc(fpr1, tpr1)
auc2 = metrics.auc(fpr2, tpr2)
plt.figure(figsize=(8,8))
# plot auc
plt.plot(fpr1, tpr1, color='blue', label='Test ROC curve area = %0.2f'%auc1)
plt.plot(fpr2, tpr2, color='green', label='Train ROC curve area = %0.2f'%auc2)
plt.plot([0,1],[0,1], 'r--')
plt.xlim([-0.1, 1.1])
plt.ylim([-0.1, 1.1])
plt.xlabel('False Positive Rate', size=14)
plt.ylabel('True Positive Rate', size=14)
plt.legend(loc='lower right')
plt.show()

i = np.arange(len(tpr1))
 # extracting roc values against different thresholds
 roc = pd.DataFrame({'fpr':fpr1, 'tpr':tpr1, 'tf':(tpr1-1+fpr1), 'thresholds':thresholds1}, index=i)
 # top 5 best roc occurrences
 roc.iloc[(roc.tf-0).abs().argsort()[:5]]

"""# Precision-Recall Curve"""

# Assuming Y_test has shape (7434, 2)
# If you're interested in precision-recall curve for class 1
pre, rec, thr = metrics.precision_recall_curve(Y_test[:, 1], prob_test)
plt.figure(figsize=(8, 4))
plt.plot(thr, pre[:-1], label='precision')
plt.plot(thr, rec[:-1], label='recall')
plt.xlabel('Threshold')
plt.title('Precision & Recall vs Threshold', c='r', size=16)
plt.legend()
plt.show()

"""# Hamming Loss"""

threshold = 0.5  # Adjust the threshold based on your problem
binary_preds = (preds[:, 1] > threshold).astype(int)
hamming_loss = metrics.hamming_loss(Y_test[:, 1], binary_preds)
print(hamming_loss)

"""# Jaccard Score"""

jaccard = metrics.jaccard_score(Y_test[:, 1], binary_preds)
jaccard

"""# Cross-entropy loss"""

cross_entropy_loss = metrics.log_loss(Y_test[:, 1], prob_test)
cross_entropy_loss

"""# Testing"""

def img_plot(arr,index=0):
    plt.title('Test Image')
    plt.imshow(arr[index])

index = 1000
img_plot(X_test, index)

def img_plot(arr,index=0):
    plt.title('Test Image')
    plt.imshow(arr[index])
index = 4000
input = X_test[index:index+1]
pred = model.predict(input)[0].argmax()
label = Y_test[index].argmax()
print('Predicted Value using  cnn model',pred)
print("True Value",label)

"""# Model Save"""

model.save('bestcancer.keras')

from tensorflow.keras.models import load_model

loaded_model = load_model('bestcancer.keras')